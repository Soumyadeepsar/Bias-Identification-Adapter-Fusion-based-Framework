{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaV1w2RLIjih"
      },
      "outputs": [],
      "source": [
        "### training of single-task adapters\n",
        "!pip -q install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "YbXC3tUuFeKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq adapters datasets"
      ],
      "metadata": {
        "id": "g24invwztPD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "import torch\n",
        "from adapters import AutoAdapterModel\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, EvalPrediction\n",
        "from adapters import AdapterTrainer\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Je6POLsVFmeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict"
      ],
      "metadata": {
        "id": "Ax3jS_JQxucj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset MBIB\n",
        "dataset = load_dataset(\"mediabiasgroup/mbib-base\")\n",
        "#dataset = load_dataset(\"rotten_tomatoes\")\n",
        "dataset.num_rows"
      ],
      "metadata": {
        "id": "gu6AWS19tQ2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## shuffling dataset split of respective bias\n",
        "dataset1=dataset['text_level_bias'].shuffle(seed=42)"
      ],
      "metadata": {
        "id": "On-1EZWqt5qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing the nan value in dataset1['text']  with ' ' (space)\n",
        "\n",
        "dataset1 = dataset1.map(lambda examples: {'text': [str(x).replace('nan', ' ') for x in examples['text']]}, batched=True)\n"
      ],
      "metadata": {
        "id": "fHlz6Oxwrvuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating split of dataset1 into train, dev, test\n",
        "\n",
        "dataset1 = dataset1.train_test_split(test_size=0.4, seed=42,shuffle=False)\n",
        "dataset1['test'] = dataset1['test'].train_test_split(test_size=0.5, seed=42,shuffle=False)\n",
        "dataset1['validation'] = dataset1['test']['train']\n",
        "dataset1['test'] = dataset1['test']['test']\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7f7BD4MYwGjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base-mnli\")\n",
        "\n",
        "def encode_batch(batch):\n",
        "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
        "  #return tokenizer(, max_length=512, truncation=True, padding=\"max_length\")\n",
        "  return tokenizer(batch[\"text\"], padding= True,truncation=True, max_length=512)\n",
        "\n",
        "# Encode the input data\n",
        "dataset1 = dataset1.map(encode_batch, batched=True)\n",
        "# The transformers model expects the target class column to be named \"labels\"\n",
        "dataset1 = dataset1.rename_column(original_column_name=\"label\", new_column_name=\"labels\")\n",
        "# Transform to pytorch tensors and only output the required columns\n",
        "dataset1.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "id": "QoUgF0f4tTHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Configuration and pre-trained model is being downloaded\n",
        "config = AutoConfig.from_pretrained(\"microsoft/deberta-base-mnli\")\n",
        "model = AutoAdapterModel.from_pretrained(\n",
        "    \"microsoft/deberta-base-mnli\",\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "id": "azc1RtjBlLAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new adapter\n",
        "\n",
        "model.add_adapter(\"text_level_bias_deberta-mnli\", config=\"seq_bn\")\n",
        "\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    \"text_level_bias_deberta-mnli\",\n",
        "    num_labels=2,\n",
        "    id2label={ 0:0, 1:1}\n",
        "  )\n",
        "\n",
        "# Activate the adapter\n",
        "model.train_adapter(\"text_level_bias_deberta-mnli\")\n"
      ],
      "metadata": {
        "id": "sxBWG19ctVVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "ltcKYPdjLfsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import TrainingArguments, EvalPrediction, EarlyStoppingCallback\n",
        "from adapters import AdapterTrainer\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1.2e-4,\n",
        "    num_train_epochs=6,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    #logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    #overwrite_output_dir=True,\n",
        "    load_best_model_at_end=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  f1 = f1_score(p.label_ids, preds, average='macro')\n",
        "  return {\n",
        "      'macro_f1': f1,\n",
        "  }\n",
        "\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset1[\"train\"],\n",
        "    eval_dataset=dataset1[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ],
      "metadata": {
        "id": "ACq7uCbAtVSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "ckGVLPKstVQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define your compute_metrics function\n",
        "def compute_macro_f1(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = np.argmax(pred.predictions, axis=1)\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  return {\n",
        "      'macro-f1': f1,\n",
        "  }\n",
        "\n",
        "# Evaluate on the test set using predict and compute_macro_f1\n",
        "predictions = trainer.predict(dataset1[\"test\"])\n",
        "metrics = compute_macro_f1(predictions)\n",
        "\n",
        "print(metrics) # Print the macro-F1 score"
      ],
      "metadata": {
        "id": "4Um2zQjVBs6x",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "Tyga3D-0JTbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Upload task adapters to huggingface-hub\n",
        "model.push_adapter_to_hub(\n",
        "    \"text_level_bias_deberta-mnli\",\n",
        "    \"text_level_bias_deberta-mnli\",\n",
        "    datasets_tag='mediabiasgroup/mbib-base'\n",
        ")"
      ],
      "metadata": {
        "id": "NwtGCJ8BrXL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Inference on test dataset from saved pre-trained adapters\n",
        "from adapters import AutoAdapterModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model = AutoAdapterModel.from_pretrained(\"microsoft/deberta-base-mnli\")\n",
        "adapter_name = model.load_adapter(\"SOUMYADEEPSAR/text_level_bias_deberta-mnli\", set_active=True)\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"microsoft/deberta-base-mnli\")\n"
      ],
      "metadata": {
        "id": "rAcyi36Cgzf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "j2t7mp22PaNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=[]\n",
        "for i in tqdm(range(len(dataset1['test']))):\n",
        "  input_data = tokenizer(dataset1['test']['text'][i], return_tensors=\"pt\",truncation=True,max_length=512)\n",
        "  outputs = model(**input_data)\n",
        "  predicted = torch.argmax(outputs[0]).item()\n",
        "  pred.append(predicted)\n"
      ],
      "metadata": {
        "id": "URijZzKiN5kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual=dataset1['test']['label']"
      ],
      "metadata": {
        "id": "1fbZ55LRRc59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(actual, pred))"
      ],
      "metadata": {
        "id": "a8iLaBBFRlkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import  f1_score\n",
        "print(f1_score(actual, pred, average='macro'))"
      ],
      "metadata": {
        "id": "axSyj4tvR_Eh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}