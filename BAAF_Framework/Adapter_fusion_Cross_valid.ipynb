{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zkVnNedPsyx"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq adapters\n",
        "!pip install -q datasets\n",
        "!pip install -q accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "lQ9srR5OLGxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "from adapters import AutoAdapterModel"
      ],
      "metadata": {
        "id": "rYCnN4DJTzAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dataset from huggingface\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"mediabiasgroup/mbib-base\")\n",
        "dataset.num_rows"
      ],
      "metadata": {
        "id": "QYZNJJkZP06y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random shuffling (inter-mixing) of dataset\n",
        "dataset1=dataset['text_level_bias'].shuffle(seed=42)\n"
      ],
      "metadata": {
        "id": "7WPPyTo4Vodf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To replace nan values in dataset1 with ' '\n",
        "\n",
        "dataset1 = dataset1.map(lambda x: {'text': ' ' if x['text'] is None else x['text']})"
      ],
      "metadata": {
        "id": "qzDuBMiXxAkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # replace nan value with empty string\n",
        "# dataset1['text'] = dataset1['text'].fillna(' ')"
      ],
      "metadata": {
        "id": "9sZopywhuuR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating 3 folds using KFold from sklearn\n",
        "kf = KFold(n_splits=3)\n"
      ],
      "metadata": {
        "id": "dYp0dPObs3v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")"
      ],
      "metadata": {
        "id": "VU5iG9w6BKBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")\n",
        "def encode_batch(batch):\n",
        "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
        "  return tokenizer(batch[\"text\"], padding=True,truncation=True, max_length=512)\n",
        "\n",
        "# Encode the input data\n",
        "dataset1 = dataset1.map(encode_batch, batched=True)\n",
        "# The transformers model expects the target class column to be named \"labels\"\n",
        "dataset1 = dataset1.rename_column(\"label\", \"labels\")\n",
        "# Transform to pytorch tensors and only output the required columns\n",
        "dataset1.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "id": "WTiRxJaaP03j",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "id2label ={0:0,1:1}\n"
      ],
      "metadata": {
        "id": "v4xyP1HNP01g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")\n",
        "model = AutoAdapterModel.from_pretrained(\n",
        "    \"cardiffnlp/twitter-roberta-base-2022-154m\",\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "id": "1HMsvkZCRGmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from adapters.composition import Fuse\n",
        "\n",
        "#Load the pre-trained adapters we want to fuse\n",
        "model.load_adapter(\"SOUMYADEEPSAR/political_bias\", with_head=False)\n",
        "model.load_adapter(\"SOUMYADEEPSAR/gender_bias\", with_head=False)\n",
        "model.load_adapter(\"SOUMYADEEPSAR/racial_bias\", with_head=False)\n",
        "model.load_adapter(\"SOUMYADEEPSAR/cognitive_bias1\", with_head=False)\n",
        "model.load_adapter(\"SOUMYADEEPSAR/text_level_bias1\", with_head=False)\n",
        "# Add a fusion layer for all loaded adapters\n",
        "adapter_setup = Fuse(\"political_bias\", \"gender_bias\", \"racial_bias\",\"cognitive_bias1\",\"text_level_bias1\")\n",
        "model.add_adapter_fusion(adapter_setup)\n",
        "\n",
        "# Add a classification head for our target task\n",
        "model.add_classification_head(\"cognitive_bias_fusion\", num_labels=len(id2label))"
      ],
      "metadata": {
        "id": "PcamfMj-P0zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train_adapter_fusion(adapter_setup)"
      ],
      "metadata": {
        "id": "axZ2iiC7P0xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "yL3fvTB3LCkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import TrainingArguments, EvalPrediction,EarlyStoppingCallback\n",
        "from adapters import AdapterTrainer\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=5.5e-5,\n",
        "    num_train_epochs=6,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    #logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    #overwrite_output_dir=True,\n",
        "    load_best_model_at_end=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  f1 = f1_score(p.label_ids, preds, average='macro')\n",
        "  return {\n",
        "      'macro_f1': f1,\n",
        "  }\n",
        "\n"
      ],
      "metadata": {
        "id": "P20kCXeKP0vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset1)):\n",
        "    train_idx1 = train_idx[:int((len(train_idx) )*0.8)]\n",
        "    val_idx = train_idx[int((len(train_idx)) *0.8):]\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    print(train_idx1)\n",
        "    print(val_idx)\n",
        "    print(test_idx)\n",
        "    print(len(train_idx1))\n",
        "    print(len(val_idx))\n",
        "    print(len(test_idx))"
      ],
      "metadata": {
        "id": "XKD_i1_qdrla",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ftc5llTHdrh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from adapters import AdapterTrainer"
      ],
      "metadata": {
        "id": "NaLGmpTedreI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores=[]\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset1)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    # 80 percent of train data from a fold was used for training and 20 percent for validation\n",
        "    train_idx1 = train_idx[:int((len(train_idx) )*0.8)]\n",
        "    val_idx = train_idx[int((len(train_idx)) *0.8):]\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    # print(len(train_idx1))\n",
        "    # print(len(val_idx))\n",
        "    # print(len(test_idx))\n",
        "    # Split dataset into training and validation based on the indices from KFold\n",
        "    train_split = dataset1.select(train_idx1)\n",
        "    val_split = dataset1.select(val_idx)\n",
        "    test_split = dataset1.select(test_idx)\n",
        "    print(len(train_split))\n",
        "    print(len(val_split))\n",
        "    print(len(test_split))\n",
        "\n",
        "    # Load the model for classification and its configuration\n",
        "\n",
        "    config = AutoConfig.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")\n",
        "\n",
        "    model = AutoAdapterModel.from_pretrained(\n",
        "    \"cardiffnlp/twitter-roberta-base-2022-154m\",\n",
        "    config=config,\n",
        "    )\n",
        "\n",
        "    from adapters.composition import Fuse\n",
        "\n",
        "    #Load the pre-trained adapters we want to fuse\n",
        "    model.load_adapter(\"SOUMYADEEPSAR/political_bias\", with_head=False)\n",
        "    model.load_adapter(\"SOUMYADEEPSAR/gender_bias\", with_head=False)\n",
        "    model.load_adapter(\"SOUMYADEEPSAR/racial_bias\", with_head=False)\n",
        "    model.load_adapter(\"SOUMYADEEPSAR/cognitive_bias1\", with_head=False)\n",
        "    model.load_adapter(\"SOUMYADEEPSAR/text_level_bias1\", with_head=False)\n",
        "\n",
        "    # Add a fusion layer for all loaded adapters\n",
        "    adapter_setup = Fuse(\"political_bias\", \"gender_bias\", \"racial_bias\",\"cognitive_bias1\",\"text_level_bias1\")\n",
        "    model.add_adapter_fusion(adapter_setup)\n",
        "\n",
        "\n",
        "    # Add a classification head for our target task\n",
        "    model.add_classification_head(\"political_bias_fusion\", num_labels=len(id2label))\n",
        "    #activating adapter fusion layers for training and freezing all other parameters of model and single-task adapters\n",
        "    model.train_adapter_fusion(adapter_setup)\n",
        "\n",
        "    # Create a Trainer instance\n",
        "    trainer = AdapterTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_split,\n",
        "        eval_dataset=val_split,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=data_collator,\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model on validation data on kth fold\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"Metrics for valid fold {fold+1}: {metrics}\")\n",
        "    #Evaluate on test data\n",
        "    outputs = trainer.predict(test_split)\n",
        "    print(f\"Metrics for test fold {fold+1}: {outputs.metrics}\")\n",
        "    f1_scores.append(outputs.metrics['test_macro_f1'])\n"
      ],
      "metadata": {
        "id": "jCqMO6qLPlle",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average of f1_scores from each folds in cross-validation\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming f1_scores is a list of f1 scores from each fold\n",
        "average_f1 = np.mean(f1_scores)\n",
        "print(f\"Average F1 score: {average_f1}\")"
      ],
      "metadata": {
        "id": "ZG2teDZF3PsR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtuX43uSP0eB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}