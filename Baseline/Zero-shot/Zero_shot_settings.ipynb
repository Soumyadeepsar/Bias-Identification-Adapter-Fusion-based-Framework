{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r-mv_AKgFg4"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyarrow==15.0.1\n",
        "!pip install -q datasets\n",
        "!pip install -q langchain-groq\n",
        "from datasets import Dataset, load_dataset\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from langchain_groq import ChatGroq\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nJ7Yh5PAgcbr"
      },
      "outputs": [],
      "source": [
        "dataset1=load_dataset(\"mediabiasgroup/mbib-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9I1qBpidTYK"
      },
      "outputs": [],
      "source": [
        "# feature in dataset of huggingface( name of splits in dataset\n",
        "\n",
        "print(dataset1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvSwboYykOfv"
      },
      "outputs": [],
      "source": [
        "# A particular bias chosen at a time\n",
        "dataset2=pd.DataFrame(dataset1['gender_bias'].shuffle(seed=42))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQvtMrmBkmJb"
      },
      "outputs": [],
      "source": [
        "# Chunk of 1000 datapoints\n",
        "dataset3=dataset2[2000:3000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppP_6tYxgqFV"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['GROQ_API']='Your_API_Key'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXr-r6ONgqB8"
      },
      "outputs": [],
      "source": [
        "chat = ChatGroq(temperature=0,groq_api_key='Your_API_Key', model_name='llama-3.1-70b-versatile')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "pred = []\n",
        "label = []\n",
        "misclassified = []\n",
        "max_retries = 5  # Set a limit for retries\n",
        "\n",
        "for id, row in tqdm(dataset3.iterrows()):\n",
        "    input = row['text']\n",
        "    retries = 0  # Track the number of retries for each request\n",
        "    prompt=f'Classify the following text as gender biased or unbiased. Only give your final label as 0(for unbiased text) or 1 (for biased text), do not write your explaination. Here is the text:{input}'\n",
        "\n",
        "    while retries <= max_retries:\n",
        "        try:\n",
        "            response = chat.invoke(prompt)\n",
        "            break  # Exit the retry loop if successful\n",
        "        except Exception as e:\n",
        "            retries += 1\n",
        "            if retries > max_retries:\n",
        "                print(f\"Max retries reached for input: {input}. Skipping this entry.\")\n",
        "                response = None  # You could skip processing for this entry if retries fail\n",
        "                break\n",
        "            print(f\"Error occurred: {e}. Retrying in {2 ** retries} seconds...\")\n",
        "            time.sleep(2 ** retries)  # Exponential backoff\n",
        "\n",
        "    if response is None:\n",
        "        continue  # Skip the rest if response is None\n",
        "\n",
        "    print(input)\n",
        "    print(response.content)\n",
        "    print(row['label'])\n",
        "\n",
        "    if response.content != str(row['label']):\n",
        "        misclassified.append(row['text'])\n",
        "        label.append(row['label'])\n",
        "\n",
        "    pred.append(response.content)\n",
        "    time.sleep(4)  # Control the rate of requests\n"
      ],
      "metadata": {
        "id": "Ge2oCTQ5COcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YD6bF319rMS"
      },
      "outputs": [],
      "source": [
        "act=dataset3['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AxhIX1Nc90ZK"
      },
      "outputs": [],
      "source": [
        "len(act)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV8YxuU79lRM"
      },
      "outputs": [],
      "source": [
        "# converting string labels to int type data\n",
        "pred=[int(i) for i in pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kERrbL_SQb-J"
      },
      "outputs": [],
      "source": [
        "## result for corresponding chunk\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(act,pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}