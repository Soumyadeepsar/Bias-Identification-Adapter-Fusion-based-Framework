{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfWL-NSAK85b"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyarrow==15.0.1\n",
        "!pip install -q datasets\n",
        "!pip install -q langchain-groq langchain\n",
        "from datasets import Dataset, load_dataset\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from langchain_groq import ChatGroq\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1=load_dataset(\"mediabiasgroup/mbib-base\")"
      ],
      "metadata": {
        "id": "diM2XPdtLTIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatGroq(temperature=0,groq_api_key='Your_API_key', model_name='llama-3.1-70b-versatile')"
      ],
      "metadata": {
        "id": "elNSTtvbLW73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset2=pd.DataFrame(dataset1['political_bias'].shuffle(seed=42))\n"
      ],
      "metadata": {
        "id": "qiTEtAfjLXCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## chunk\n",
        "dataset3=dataset2[2000:2500]"
      ],
      "metadata": {
        "id": "VgfKunzDhkFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Randomly sampling 3 data-points from each class from the entire dataset\n",
        "df3=dataset2[dataset2['label']==1].sample(n=3,random_state=42)\n",
        "df4 = dataset2[dataset2['label']==0].sample(n=3,random_state=42)"
      ],
      "metadata": {
        "id": "2ey2i1bMfLnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = pd.concat([df4, df3])"
      ],
      "metadata": {
        "id": "2RsEWY_ULW_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df=sampled_df[['text','label']]"
      ],
      "metadata": {
        "id": "2H95dKvqfTbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise_list = []\n",
        "\n",
        "# Iterate over the DataFrame rows\n",
        "for index, row in sampled_df.iterrows():\n",
        "    # Create a dictionary for each row\n",
        "    pair_dict = {'text': row['text'], 'label': row['label']}\n",
        "    # Append the dictionary to the list\n",
        "    pairwise_list.append(pair_dict)\n",
        "\n",
        "print(pairwise_list)"
      ],
      "metadata": {
        "id": "w7tSv9oofWvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples=pairwise_list"
      ],
      "metadata": {
        "id": "7Lwy97c1fdy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "example_formatter_template = \"\"\"text: {text}\n",
        "label: {label}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\", \"label\"],\n",
        "    template=example_formatter_template,\n",
        ")"
      ],
      "metadata": {
        "id": "wL4mnYt4fhTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "\n",
        "    examples=examples,\n",
        "\n",
        "    example_prompt=example_prompt,\n",
        "\n",
        "    prefix=\"Here are some examples of politically biased and unbiased text given below. The label for biased text is 1 and that of unbiased is 0:\\n\",\n",
        "\n",
        "    suffix=\"Now only give the final label(0 or 1) indicating unbiased(0) or biased(1) text.\\n\\ntext: {input}\\nlabel: \",\n",
        "\n",
        "    input_variables=[\"input\"],\n",
        "\n",
        "    example_separator=\"\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "84yZj51JflZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=few_shot_prompt|chat"
      ],
      "metadata": {
        "id": "7LGc2vTIfsWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset3"
      ],
      "metadata": {
        "id": "JkObgii7fzbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "pred = []\n",
        "label = []\n",
        "misclassified = []\n",
        "max_retries = 5  # Set a limit for retries\n",
        "\n",
        "for id, row in tqdm(dataset3.iterrows()):\n",
        "    input = row['text']\n",
        "    retries = 0  # Track the number of retries for each request\n",
        "\n",
        "    while retries <= max_retries:\n",
        "        try:\n",
        "            response = chain.invoke({'input': input})\n",
        "            break  # Exit the retry loop if successful\n",
        "        except Exception as e:\n",
        "            retries += 1\n",
        "            if retries > max_retries:\n",
        "                print(f\"Max retries reached for input: {input}. Skipping this entry.\")\n",
        "                response = None  # You could skip processing for this entry if retries fail\n",
        "                break\n",
        "            print(f\"Error occurred: {e}. Retrying in {2 ** retries} seconds...\")\n",
        "            time.sleep(2 ** retries)  # Exponential backoff\n",
        "\n",
        "    if response is None:\n",
        "        continue  # Skip the rest if response is None\n",
        "\n",
        "    #print(input)\n",
        "    print(response.content)\n",
        "    print(row['label'])\n",
        "\n",
        "    if response.content != str(row['label']):\n",
        "        misclassified.append(row['text'])\n",
        "        label.append(row['label'])\n",
        "\n",
        "    pred.append(response.content)\n",
        "    time.sleep(4)  # Control the rate of requests\n"
      ],
      "metadata": {
        "id": "eKJWT-ajiG7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=[int(x) for x in pred]"
      ],
      "metadata": {
        "id": "S997h4_bPzWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Macro-F1-score in the classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(dataset3['label'], pred))"
      ],
      "metadata": {
        "id": "GbNFDI1rQnxh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}